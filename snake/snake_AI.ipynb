{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EN8DZpwAU10"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from gymnasium import spaces\n",
        "import gymnasium as gym\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2274sN_Ji04"
      },
      "outputs": [],
      "source": [
        "class Snake_game(gym.Env):\n",
        "  metadata = {'render.modes': ['console','rgb_array']}\n",
        "\n",
        "  n_actions = 3\n",
        "  LEFT = 0\n",
        "  STRAIGHT = 1\n",
        "  RIGHT = 2\n",
        "\n",
        "  EMPTY = 0\n",
        "  SNAKE = 1\n",
        "  WALL = 2\n",
        "  FOOD = 3\n",
        "\n",
        "  REWARD_WALL_HIT = -20 #should be lower than -1 * REWARD_PER_STEP_TOWARDS_FOOD to avoid hitting walls on purpose\n",
        "  REWARD_PER_STEP_TOWARDS_FOOD = 1 #reward the agent for moving towards food, and penalize for moving away\n",
        "  REWARD_PER_FOOD = 50\n",
        "  MAX_STEPS_AFTER_FOOD = 200\n",
        "\n",
        "  def grid_distance(self,pos1,pos2):\n",
        "    return np.linalg.norm(np.array(pos1,dtype=np.float32)-np.array(pos2,dtype=np.float32))\n",
        "\n",
        "  def __init__(self, grid_size=10):\n",
        "    super(Snake_game, self).__init__()\n",
        "    self.stepnum = 0\n",
        "    self.last_food_step=0\n",
        "\n",
        "    self.grid_size = grid_size\n",
        "    self.grid = np.zeros( (self.grid_size, self.grid_size) ,dtype=np.uint8) + self.EMPTY\n",
        "    self.grid[0,:] = self.WALL\n",
        "    self.grid[:,0] = self.WALL\n",
        "    self.grid[self.grid_size-1,:] = self.WALL\n",
        "    self.grid[:,self.grid_size-1] = self.WALL\n",
        "    #wall at the egdes\n",
        "\n",
        "    self.snake_coordinates = [ (1,1), (2,1) ] #Start in upper left corner\n",
        "    for coord in self.snake_coordinates:\n",
        "      self.grid[ coord ] = self.SNAKE  #put snake on grid\n",
        "\n",
        "    self.grid[3,3] = self.FOOD  #Start in upper left corner\n",
        "    self.head_dist_to_food = self.grid_distance(self.snake_coordinates[-1],np.argwhere(self.grid==self.FOOD)[0] )\n",
        "\n",
        "    self.init_grid = self.grid.copy()\n",
        "    self.init_snake_coordinates = self.snake_coordinates.copy()\n",
        "\n",
        "    self.action_space = spaces.Discrete(self.n_actions)\n",
        "\n",
        "    self.observation_space = spaces.Dict(\n",
        "      spaces={\n",
        "        \"position\": spaces.Box(low=0, high=(self.grid_size-1), shape=(2,), dtype=np.int32),\n",
        "        \"direction\": spaces.Box(low=-1, high=1, shape=(2,), dtype=np.int32),\n",
        "        \"grid\": spaces.Box(low = 0, high = 3, shape = (self.grid_size, self.grid_size), dtype=np.uint8),\n",
        "      })\n",
        "\n",
        "  def reset(self, seed=None):\n",
        "    # Reset to initial positions\n",
        "    self.stepnum = 0\n",
        "    self.last_food_step = 0\n",
        "    self.grid = self.init_grid.copy()\n",
        "    self.snake_coordinates = self.init_snake_coordinates.copy()\n",
        "\n",
        "    self.head_dist_to_food = self.grid_distance(self.snake_coordinates[-1], np.argwhere(self.grid == self.FOOD)[0])\n",
        "\n",
        "    if seed is not None:\n",
        "      np.random.seed(seed)\n",
        "\n",
        "    obs = self._get_obs()\n",
        "    info = {}  # An empty dictionary for info (can be extended with additional information if needed)\n",
        "\n",
        "    return obs, info  # Return both the observation and info as a tuple\n",
        "\n",
        "  def _get_obs(self):\n",
        "    direction = np.array(self.snake_coordinates[-1]) - np.array(self.snake_coordinates[-2])\n",
        "    #return observation in the format of self.observation_space\n",
        "    return {\"position\": np.array(self.snake_coordinates[-1],dtype=np.int32),\n",
        "            \"direction\" : direction.astype(np.int32),\n",
        "            \"grid\": self.grid}\n",
        "\n",
        "  def step(self, action):\n",
        "    #Get direction for snake\n",
        "    direction = np.array(self.snake_coordinates[-1]) - np.array(self.snake_coordinates[-2])\n",
        "    if action == self.STRAIGHT:\n",
        "      step = direction #step in the firection the snake faces\n",
        "    elif action == self.RIGHT:\n",
        "      step = np.array( [direction[1], -direction[0]] )  #turn right\n",
        "    elif action == self.LEFT:\n",
        "      step = np.array( [-direction[1], direction[0]] )   #turn left\n",
        "    #New head coordinate\n",
        "    new_coord = (np.array(self.snake_coordinates[-1]) + step).astype(np.int32)\n",
        "    #grow snake\n",
        "    self.snake_coordinates.append( (new_coord[0],new_coord[1]) ) #convert to tuple so we can use it to index\n",
        "\n",
        "\n",
        "    #Check what is at the new position\n",
        "    new_pos = self.snake_coordinates[-1]\n",
        "    new_pos_type = self.grid[new_pos]\n",
        "    self.grid[new_pos] = self.SNAKE #this position is now occupied by the snake\n",
        "    done = False\n",
        "    reward = 0 #by default the game goes on and no reward\n",
        "    if new_pos_type == self.FOOD:\n",
        "        reward += self.REWARD_PER_FOOD\n",
        "        self.last_food_step = self.stepnum\n",
        "        #Put down a new food item\n",
        "        empty_tiles = np.argwhere(self.grid==self.EMPTY)\n",
        "        if len(empty_tiles):\n",
        "            new_food_pos=empty_tiles[np.random.randint(0,len(empty_tiles))]\n",
        "            self.grid[new_food_pos[0],new_food_pos[1]] = self.FOOD\n",
        "        else:\n",
        "            done = True #no more tiles to put the food to\n",
        "    else:\n",
        "        self.grid[ self.snake_coordinates[0] ] = self.EMPTY\n",
        "        self.snake_coordinates = self.snake_coordinates[1:]\n",
        "        if  (new_pos_type == self.WALL) or (new_pos_type == self.SNAKE):\n",
        "            done = True #stop if we hit the wall or the snake\n",
        "            reward += self.REWARD_WALL_HIT #penalty for hitting walls/tail\n",
        "#        else:\n",
        "#          reward += self.REWARD_PER_STEP\n",
        "# ^ infinite looper\n",
        "    head_dist_to_food_prev = self.head_dist_to_food\n",
        "    self.head_dist_to_food = self.grid_distance( self.snake_coordinates[-1],np.argwhere(self.grid==self.FOOD)[0] )\n",
        "    if head_dist_to_food_prev > self.head_dist_to_food:\n",
        "      reward += self.REWARD_PER_STEP_TOWARDS_FOOD #reward for getting closer to food\n",
        "    elif head_dist_to_food_prev < self.head_dist_to_food:\n",
        "      reward -= self.REWARD_PER_STEP_TOWARDS_FOOD #penalty for getting further\n",
        "    if ( (self.stepnum - self.last_food_step) > self.MAX_STEPS_AFTER_FOOD ):\n",
        "      done = True\n",
        "    self.stepnum += 1\n",
        "    return  self._get_obs(), reward, done, False, {}\n",
        "\n",
        "  def snake_plot(self, plot_inline=False):\n",
        "    wall_ind = (self.grid==self.WALL)\n",
        "    snake_ind = (self.grid==self.SNAKE)\n",
        "    food_ind = (self.grid==self.FOOD)\n",
        "    #Create color array for plot, default white color\n",
        "    Color_array=np.zeros((self.grid_size,self.grid_size,3),dtype=np.uint8)+255 #default white\n",
        "    Color_array[wall_ind,:]= np.array([0,0,0]) #black walls\n",
        "    Color_array[snake_ind,:]= np.array([0,255,0]) #bluish snake\n",
        "    Color_array[food_ind,:]= np.array([255,0,0]) #green food\n",
        "    return Color_array\n",
        "\n",
        "  def render(self, mode='rgb_array'):\n",
        "    if mode == 'console':\n",
        "      print(self.grid)\n",
        "    elif mode == 'rgb_array':\n",
        "      return self.snake_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIJ6cnnGAbwN"
      },
      "outputs": [],
      "source": [
        "#Built in environment check\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "env = Snake_game()\n",
        "# If the environment doesn't follow the interface, an error will be thrown\n",
        "check_env(env, warn=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDlKR5W8Agnd"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "import os\n",
        "\n",
        "#Logging\n",
        "log_dir = \"log\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "# Instantiate the env\n",
        "env = Snake_game()\n",
        "# wrap it\n",
        "env = Monitor(env, log_dir)\n",
        "#Callback, this built-in function will periodically evaluate the model and save the best version\n",
        "eval_callback = EvalCallback(env, best_model_save_path='./log/',\n",
        "log_path='./log/', eval_freq=5000,\n",
        "deterministic=False, render=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNImdBZRAp-c"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "PPO_model_args = {\n",
        "  \"learning_rate\": 0.03, #rate at which models weights change\n",
        "  \"gamma\": 0.60, #0.99, discount factor for futurer rewards, between 0 (only immediate reward matters) and 1 (future reward equivalent to immediate),\n",
        "  \"verbose\": 0, #change to 1 to get more info on training steps\n",
        "  \"seed\": 137, #fixing the random seed\n",
        "  \"ent_coef\": 0.20, #0, entropy coefficient, to encourage exploration\n",
        "  \"clip_range\": 0.2 #0.2, very roughly: probability of an action can not change by more than a factor 1+clip_range\n",
        "}\n",
        "\n",
        "model = PPO('MultiInputPolicy', env,**PPO_model_args)\n",
        "if os.path.exists(\"log/best_model.zip\"):\n",
        "  model.set_parameters(\"log/best_model.zip\")\n",
        "\n",
        "model.learn(6000000,callback=eval_callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcHoJ0wdAvCx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.animation as animation\n",
        "import matplotlib as mpl\n",
        "\n",
        "# Test the trained agent and save animation\n",
        "obs, _ = env.reset()\n",
        "# Framework to save animgif\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "plt.axis('off')\n",
        "frames = []\n",
        "fps = 18\n",
        "\n",
        "n_steps = 1000000\n",
        "tot_reward = 0\n",
        "for step in range(n_steps):\n",
        "  # Preprocess the observation to match the model's input format\n",
        "  action, _ = model.predict(obs, deterministic=False)\n",
        "  obs, reward, done, trunc, info = env.step(action)\n",
        "  tot_reward += reward\n",
        "  print(\"Step {}\".format(step + 1), \"Action: \", action, 'Tot. Reward: %g' % (tot_reward))\n",
        "  frames.append([ax.imshow(env.render(mode='rgb_array'), animated=True)])\n",
        "  if done:\n",
        "    print(\"Game over!\", \"tot. reward=\", tot_reward)\n",
        "    break\n",
        "\n",
        "\n",
        "fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)  # To remove white bounding box\n",
        "anim = animation.ArtistAnimation(fig, frames, interval=int(1000 / fps), blit=True, repeat_delay=1000)\n",
        "anim.save(\"snake_best.gif\", dpi=150)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
